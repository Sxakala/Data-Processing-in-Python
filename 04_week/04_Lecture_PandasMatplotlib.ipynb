{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4: Pandas\n",
    "\n",
    "October 22, 2024\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "0. Technical notes\n",
    "1. Recap\n",
    "2. Pandas :: [https://pandas.pydata.org](https://pandas.pydata.org)\n",
    "3. Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Midterm\n",
    "\n",
    "- 80 minutes in class\n",
    "- NO artificial intelligence helpers\n",
    "- open book = lectures, google, stackoverflow\n",
    "\n",
    "### Project\n",
    "\n",
    "- slowly start to look for your colleagues (pairs, if somebody super alone group of three)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap - NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions related to the course\n",
    "\n",
    "We are starting Week 4. \n",
    "\n",
    "Do you need anything to help with?\n",
    "\n",
    "What would you improve/what do you miss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Git + Github:\n",
    "\n",
    "- Are you familiar with it?\n",
    "- Have you tried to create a repository?\n",
    "\n",
    "- `!pip` + alternatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Python version {sys.version}')\n",
    "print(f'Pandas version {pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling imports, where python looks for modules\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas** is a powerful and widely used open-source data manipulation and analysis library in Python. \n",
    "It provides data structures like `DataFrame` and `Series`, which make it easy to work with structured data like tables (like in a spreadsheet or SQL). \n",
    "It is built on top of `numpy`, making it efficient for numerical computations.\n",
    "\n",
    "### Why is `pandas` useful?\n",
    "\n",
    "1. **Ease of Use**: Pandas makes it straightforward to perform data analysis with a simple, readable syntax. Tasks like filtering data, aggregating results, and reshaping data become much easier than using basic Python constructs.\n",
    "2. **Data Manipulation**: With `pandas`, you can clean, process, and manipulate data. It offers operations for handling missing data, merging datasets, group-by operations, and more.\n",
    "3. **Data I/O**: It supports loading data from and writing data to various file formats such as CSV, Excel, JSON, SQL databases, and more.\n",
    "4. **Efficient Handling**: It provides excellent memory and performance optimization for handling large datasets efficiently, thanks to its underlying use of `numpy`.\n",
    "5. **Integration with Other Libraries**: Pandas integrates well with other data analysis and machine learning libraries in Python, such as `matplotlib` (for plotting), `scikit-learn` (for ML), and `statsmodels` (for statistical analysis).\n",
    "\n",
    "\n",
    "### Main Data Structures in `pandas`\n",
    "\n",
    "1. **Series**: A one-dimensional labeled array that can hold any data type.\n",
    "2. **DataFrame**: A two-dimensional labeled data structure with columns of potentially different data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structures in pandas\n",
    "\n",
    "### Series\n",
    "* 1D labeled array able to hold any data type (int, str, float, Python objects, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1,-1,1,-1]).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data` (in the example above) can be:\n",
    "\n",
    "* a dict\n",
    "* a list\n",
    "* an ndarray\n",
    "* a scalar value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of from dict and a scalar value below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case of dictionary\n",
    "pd.Series({'cat':1, 'dog':2, 'parrot':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(np.arange(5), index=['a', 'b', 'c', 'd','e'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* a key difference between Series/pandas and ndarray: operations between Series automatically align the data based on label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series({\"Vítek\": 5, \"Martin\": 10, \"Honza\": 0})\n",
    "\n",
    "b = pd.Series({\"Martin\": 20, \"Honza\": 15, \"Vítek\": 5})\n",
    "\n",
    "print(f\"A:\\n{a}\\nB:\\n{b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a + b # operations are done by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [5,10,0]\n",
    "b = [20,15,5]\n",
    "\n",
    "np.array(a) + np.array(b) # now works as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* looping through (value-by-value) usually not necessary, remember the case of np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['Vítek']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  DataFrame\n",
    "\n",
    "* a 2D labeled data structure with columns of potentially different types\n",
    "* like a spreadsheet or SQL table, or a dict of Series objects\n",
    "* the most frequently used pandas object \n",
    "* can be created:\n",
    "    * typically by reading a csv file\n",
    "    * dict of 1D ndarrays, lists, dicts, Series\n",
    "    * 2D numpy.ndarray\n",
    "    * a Series\n",
    "    * another DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"var\": [1, 2, 3], \"column2\": [0, 0, 0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(\n",
    "    [{\"var\": 1, \"column2\": 0}, {\"var\": 2, \"column2\": 0}, {\"var\": 3, \"column2\": 0}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.columns, a.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dict of Series\n",
    "d = {\n",
    "    \"one\": pd.Series([1.0, 2.0, 3.0], index=[\"a\", \"e\", \"c\"]),\n",
    "    \"two\": pd.Series([2.0, 1.0, 3.0, 4.0], index=[\"b\", \"a\", \"c\", \"d\"]),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data unzipped, we can load them into Python, specifically using Pandas tools.\n",
    "\n",
    "### Data I/O (in/out)\n",
    "* CSV, JSON, HTML, Excel, HDF5, SQL, pickle, ...\n",
    "    * for specific details, see [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html)\n",
    "* `pd.read_csv()` is the workhorse for reading text files\n",
    "    * large number of params means great flexibility when getting data in\n",
    "    \n",
    "We will work with the course evaluation data from FSV.\n",
    "  * each observation is a response to the following questionare (... hope it reminds you of something)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the \"raw\" data for one particular year\n",
    "df = pd.read_csv('04_auxiliary/data_2017_zs.csv', sep = ';', on_bad_lines= 'skip')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data have column names in czech, let's rename them\n",
    "# if you do not want to reassign, you can provide arg. \"inplace = True\"\n",
    "df = df.rename(columns = {\n",
    "    'cislo_dot' : 'number',\n",
    "    'kod_predm' : 'course_code',\n",
    "    'nazev_predm' : 'course_title',\n",
    "    'prednasejici' : 'teachers',\n",
    "    'cvicici' : 'seminar_leaders',\n",
    "    't1': 'c_value',\n",
    "    't2': 'c_improve', \n",
    "    'katedra_code' : 'department_code'\n",
    "})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterative\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set column named \"course_code\" to be an index (or you can use \"inplace\" option again)\n",
    "df.set_index('number', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.course_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the data but refrain from drawing the conclusions\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of original data, so if you mess up, can go back to this\n",
    "# not that smart when you are working with the large data\n",
    "df_copy = df.copy(deep = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `pd.DataFrame.copy()`:\n",
    "    * deep: modifications to the data or indices of the copy will not be reflected in the original object\n",
    "    * shallow: any changes to the data of the original will be reflected in the shallow copy (and vice versa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to call it as a function\n",
    "# df.shape() # it si an attribute not a function\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classical data summarization\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "df.info() # more detailed info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory usage of each column in bytes (useful when working with the larger datasets)\n",
    "df.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.memory_usage().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.memory_usage().sum() / 1024**2 # in MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.memory_usage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* you can treat a DataFrame semantically like a dict of like-indexed Series objects\n",
    "    * getting, setting, and deleting columns works with the same syntax as the analogous dict operations\n",
    "\n",
    "## Indexing/Selection\n",
    "\n",
    "| Operation                      | Syntax        |  Result   |\n",
    "|--------------------------------|---------------|-----------|\n",
    "| Select column                  | df[col]       |  Series   |\n",
    "| Select row by label            | df.loc[label] |  Series   |\n",
    "| Select row by integer location | df.iloc[loc]  |  Series   |\n",
    "| Slice rows                     | df[5:10]      | DataFrame |\n",
    "| Select rows by boolean vector  | df[bool_vec]  | DataFrame |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives us series\n",
    "df['course_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this demonstrates usefulness of proper column naming\n",
    "df.course_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple columns -> gives us dataframe\n",
    "df[['course_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just one column: just convenience (if column name has a space or dot, you are screwed)\n",
    "#naming conventions: no special character, underscore for spaces, no CZECH chars! informative and short\n",
    "df.course_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset of columns you want \n",
    "df[['course_title','teachers']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all columns \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding columns (first adding, so we have something to drop)\n",
    "df['tmp'] = '11/10'\n",
    "# you can also use assign function, if new column should be a function of original column \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sumq1q2'] = df.q1+df.q2\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column (you can also use 'del' (a general python comand for deleting)\n",
    "df.drop('tmp', axis = 1, inplace = True) # axis to specify you want to drop column, inplace operation in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.department_code == 'ies') & (df.teachers.str.contains('Červinka'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.department_code == 'ies']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location and Idioms\n",
    "* `.loc` selects data by the label of the rows and columns (as opposed to the `.iloc`) integer location\n",
    "* we can also use `.loc` for subsetting based on condition(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[5:25:3, ['department_code','teachers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[5:25:3, [-2, 2]] # iloc is integer based, different from loc which is label based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What might be a problematic difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset using a mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only observations for IES only\n",
    "df_ies = df.loc[df['department_code'] == 'ies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only observations for Advanced Econometrics\n",
    "df.loc[df['course_title'] == 'Advanced Econometrics'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub-setting based on multiple conditions: AE and non-missing comment on what to improve\n",
    "df.loc[(df['course_title'] == 'Advanced Econometrics') & (~df['c_improve'].isnull())].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sometimes, we don't have a clear list of columns to be selected ready, e.g. how to select columns from q1 to q13? \n",
    "    * using actual list of column names :(\n",
    "        * be lazy!\n",
    "    * or ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list comprehension\n",
    "print([x for x in df.columns if \"q\" in x])  # by substring\n",
    "print([x for x in df.columns if (len(x) == 2) | (len(x) == 3)])  # by length\n",
    "print([x for x in df.columns if x.startswith(\"q\")])  # by first letter\n",
    "# by regular expression is the safest - q and then at most 2 digit number -> later in course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in df.columns if 'q' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q = df[[x for x in df.columns if 'q' in x]]\n",
    "df_q.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using functions on pandas objects\n",
    "\n",
    "| Operation          | Function              |\n",
    "|--------------------|-----------------------|\n",
    "| Row or Column-wise | `apply()`             |\n",
    "| Aggregation        | `agg() / transform()` |\n",
    "| Elementwise        | `applymap()`          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tablewise**\n",
    "* DFs and Series can be arguments of the functions\n",
    "* if multiple functions need to be called in a sequence, use `pipe()` method, also called the method chaining\n",
    "    * often used in the data science setting\n",
    "    * inspired by unix pipes and dplyr (%>%) operator in R "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Row or Column-wise Function Application**\n",
    "* `apply()` is extremely powerful, when used with some brainpower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q.apply(np.mean, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using lambda - anonymous function\n",
    "# standardization to unit variance\n",
    "df_q.apply(lambda x: (x - np.mean(x)) / np.std(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using custom function, with arguments (could have also be done with lambda)\n",
    "def add_and_substract(df, sub=1, add=1):\n",
    "    return df - sub + add\n",
    "\n",
    "\n",
    "df_q.apply(add_and_substract, args=(0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A little bit more sophisticated:  show the longest comment\n",
    "df.loc[df[\"c_value\"].apply(lambda x: len(str(x))).idxmax(), \"c_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"c_value\"].apply(lambda x: len(str(x))).idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.idxmax?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"c_value\"].apply(lambda x: len(str(x))).idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[max(df[\"c_value\"].apply(lambda x: len(str(x)))) == df[\"c_value\"].apply(lambda x: len(str(x)))] # alternative to find max and its index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.index[max(df[\"c_value\"].apply(lambda x: len(str(x)))) == df[\"c_value\"].apply(lambda x: len(str(x)))]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggregation**\n",
    "* *`aggregate()`* and *`transform()`*\n",
    "* aggregation allows multiple aggregation operations in a single concise way\n",
    "* `transform()` method returns an object that is indexed the same as the original\n",
    "   * allows multiple operations at the same time, instead of one-by-one as `aggregate()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregating simple function is the same as apply\n",
    "df_q.agg(np.mean, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_q.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregating more functions more interesting (you could do your own describe function easily! )\n",
    "df_q.aggregate([np.mean, np.std, np.min, np.max], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_q.aggregate([pd.Series.mean, pd.Series.std, pd.Series.min, pd.Series.max], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregating using dictionary, i.e. column specific aggregation \n",
    "df_q.agg({'q1' : [np.mean], 'q2': np.std, 'q3': [np.mean, np.std, np.var]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using single function, the same as with apply\n",
    "df_q.transform(lambda x: np.power(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using multiple functions (can also be done using dictionary as in the case of aggregate)\n",
    "df_q.transform([np.abs, lambda x: x + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.teachers.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.teachers.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% of missing observations for specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['q1'].isnull().sum() / df['q1'].isnull().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% of missing observations for all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.isnull().sum()/df.shape[0]).sort_values().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.isnull().sum()/df.shape[0]).sort_values().plot.bar(ylim=(0,1),grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Matplotlib <a name=\"introduction\"></a>\n",
    "\n",
    "* \"A picture is worth a thousand words.\"\n",
    "    * more like \"A picture is worth a few lines of code.\"\n",
    "* development started in 2003 by John D. Hunter, a neurobiologist (inspired by MATLAB software)\n",
    "* generating basic plots in *matplotlib* is simple, mastering the library can be little bit less pleseant (we skip this part)\n",
    "* you can have as much control as you want, but you can also concede as much control as you want \n",
    "* [**gallery**](https://matplotlib.org/stable/gallery/index.html)\n",
    "    * can get help to problems like \"I want to make a figure that looks something I've seen somewhere.\" (hard to google)\n",
    "* plotting consists of many layers, from general 'contour this 2D array' to very specific 'color this screen pixel'\n",
    "    * key is allowing both levels to coexist in one package\n",
    "* *matplotlib* has 2 interfaces:\n",
    "    1. \"state-machine environment\" (based on MATLAB)\n",
    "    2. a object-oriented interface\n",
    "* this often creates confusion (multiple, conflicting, solutions on the web)\n",
    "* another common confusion is the relationship of *Matplotlib, pyplot and pylab*\n",
    "    * Matplotlib is the whole package\n",
    "    * `matplotlib.pyplot` is a module in matplotlib\n",
    "    * `pylab` is a a convenience module doing a bulk import of `pyplot` and `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [anatomy of the plot](https://matplotlib.org/examples/showcase/anatomy.html) from matplotlib\n",
    "\n",
    "<img src= \"https://matplotlib.org/_images/anatomy.png\" width= \"600\" height=\"400\">\n",
    "\n",
    "* the *figure* keeps track of all the child *Axes*, titles,legends, etc.\n",
    "    * the figure can have any number of *Axes*\n",
    "* *Axes* is 'a plot', i.e. the region of the image with the data space\n",
    "    * given *Axes* object can only be in one Figure\n",
    "    * *Axes* contains 2 (3 in case of 3D) *Axis* objects which take care of the data limits (conrolled via `set_xlim()` method)\n",
    "    * each *Axes* has a title (`set_title()`), an x- and y-labels (`set_xlabel()`)\n",
    "* *Artist* is anything you can see on the figure, e.g. text objects, Line2D objects, etc.\n",
    "\n",
    "* `matplolib.pyplot` functions make some changes to a figure, e.g. create a figure, plot some lines, etc.\n",
    "    * the plotting functions are directed to the current axes\n",
    "\n",
    "* all of plotting functions expect `np.array` or `array-like` data objects (for majority of cases works out of the box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increasing the size of the figure\n",
    "plt.figure(figsize = (20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_styles_list = plt.style.available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1677517840825
    }
   },
   "outputs": [],
   "source": [
    "for style in plt_styles_list[:3]:\n",
    "    plt.style.use(style)\n",
    "    print(style)\n",
    "    plt.figure(figsize=(5,2))\n",
    "    plt.plot(np.sin(np.linspace(0,2*np.pi)))\n",
    "    plt.show()\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "# minimum example of pyplot\n",
    "x = np.linspace(0, 2, 100)\n",
    "\n",
    "# we can also specify only \"y\" and use default x-axis: plt.plot(x, label='linear')\n",
    "plt.figure(figsize=(5,2))\n",
    "plt.plot(x, x, label='linear',  linewidth=2.0)\n",
    "plt.plot(x, x**2, label='quadratic')\n",
    "plt.plot(x, np.sqrt(x),'k^:',label='sqrt')\n",
    "\n",
    "plt.xlabel('x label')\n",
    "plt.ylabel('y label')\n",
    "\n",
    "plt.title(\"Basic plots\")\n",
    "\n",
    "plt.legend(loc = 'best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* for multiple subplots: `fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(7, 4))`\n",
    "* call `plt.subplot()` and specify three numbers:\n",
    "    * number of rows\n",
    "    * number of columns\n",
    "    * subplot number you want to activate.\n",
    "* if subplots are too squished `plt.tight_layout()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for i in range (1, 5):\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.text(0.5,0.5, str((2, 2, i)), ha='center', fontsize = 10) #again, just a plot\n",
    "    plt.tight_layout() \n",
    "    plt.grid(True) # add the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multiple figures and axes \n",
    "def f(x):\n",
    "    return np.cos(2*np.pi*x)\n",
    "\n",
    "x1 = np.arange(0.0, 5.0, 0.1)\n",
    "x2 = np.arange(0.0, 5.0, 0.02)\n",
    "\n",
    "plt.figure(1, figsize=(5,3)) # optional, since figure(1) will be created by default\n",
    "plt.subplot(211)\n",
    "plt.plot(x1, f(x1), 'bo', x2, f(x2), 'k')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(x2, np.tan(2*np.pi*x2), 'r--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma, n = 100, 15, 10000\n",
    "x = np.random.normal(mu, sigma, n)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "# the histogram of the data\n",
    "plt.hist(x, bins = 50, density= True, facecolor='g')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Histogram of X')\n",
    "\n",
    "# meaningful text\n",
    "plt.text(60, .025, f'$\\mu={mu},\\ \\sigma={sigma}$')\n",
    "# tail events text\n",
    "plt.text(40, .00025, f\"I've seen better times.\")\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(111)\n",
    "# plt.figure(figsize=(5,4))\n",
    "t = np.arange(0.0, 5.0, 0.01)\n",
    "s = np.cos(2*np.pi*t)\n",
    "\n",
    "line, = plt.plot(t, s, lw=2)\n",
    "plt.annotate(\"'go home, you are drunk'-arrow'\", xy=(4.5, -1.7), xytext=(0.3, 1.7),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             )\n",
    "plt.ylim(-2, 2)\n",
    "\n",
    "# actually saving\n",
    "plt.savefig('04_auxiliary/go_home_you_drunk.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
